---
tags:
  - BasicMath
  - LinearAlgebra
relation:
  - "[[Linear Algebra]]"
  - "[[NumericalCalculate]]"
teacher: 宁文杰
---
## 梳理最优化理论

### 前期基础知识储备

#### 正定矩阵

相当于标量中的正数

#### 半正定阵

相当于标量中的非负数

#### 矩阵的特征值

构造方程
$$
\det(A - \lambda I) = \det \begin{pmatrix} 4 - \lambda & 1 \\ 2 & 3 - \lambda \end{pmatrix} = 0
$$
然后可得lambda的值即为特征值

> 正定矩阵的判断依据之一即为矩阵对称且所有的特征值为零

### 凸函数与凸集

#### 凸函数

若函数的Hesse矩阵为正定阵则函数为严格凸函数





### 经典的线性规划问题

使用LP基本定理来解决:

- 若问题有可行解,则必有基本可行解
	- 由此得出我们可以使用令自由变量为零的方式得到一个解
- 若问题有最优解,则必有最优的基本可行解
	- 如字面

#### 单纯形法

基本画表解决技能,直接对LP基本定理的应用

- 找基变量
- 令自由变量为零
- 确认是否符合约束条件
- 用自由变量表示基变量
- 验证是否是最优解
- 若不是则寻找新的基变量进行下一步

#### 大M法

对于初始条件不好找或者找不出来的情况(如基变量总是存在等于负数的情况)

- 重新设置新变量(个数与行秩同,即初始的基变量)
- 同单纯形法计算
- 验证最后自定义变量的值是否为零(是否为自由变量)

大M法其实很像后期的罚函数法,取M为一个足够大的值,又因为变量大于等于零,所以为了取得最小值变量只能取值零,对最小值无影响



### 一维搜索(线搜索理论)

实际使用上最多的用处是计算步长

#### 初始搜索区间的确定

- 进退法

#### 区间类算法

- 二分法
- 黄金分割法

#### 函数拟合算法

- 牛顿法
	- 如何确定这样得到的xk点列具有收敛性
		- 似乎需要通过对多元函数的经典牛顿法证明来得到结论,同时产生了修正牛顿法
- 二次插值法
	- 其中取三个点并写出过此三点的二次函数进行拟合
		- 事实上,牛顿法也是一种特殊的二次插值法

### 多维搜索方法

#### 最速下降法

选取梯度的反方向作为搜索方向,步长采用一维搜索找出

- 优点
	- 全局收敛,即使初始点取得不好也可以得到答案
	- 方法简单,计算量少
- 缺点
	- 容易受细小扰动干扰
	- 在极值点附近收敛的很慢

#### 牛顿法(二次收敛型)

将函数改为向量的多维形式即可

- 优点
	- 对于正定二次型的优化问题迭代一次即可获得答案
- 缺点
	- 计算量大,需要算Hesse矩阵
	- 不能全局收敛,初始点的取值需要在极值点附近,否则无法收敛
	- 需要函数二阶可微

更新公式:    $$ \mathbf{x}_{n+1} = \mathbf{x}_n - \mathbf{H}_f(\mathbf{x}_n)^{-1} \nabla f(\mathbf{x}_n)$$

*此处要求: Hesse矩阵是正定的且非奇异的*

- 若Hesse矩阵奇异则无法得到逆矩阵
- 若Hesse矩阵非正定则无法得到函数在这附近是凸函数,无法保证函数是下降的

#### 阻尼牛顿法(二次收敛型)

由于牛顿法的步长是固定的,
$$
x_{n+1} = x_n - \frac{f'(x_n)}{f''(x_n)}
$$
可知步长lambda为1, 由此可能会导致函数错过极值点以至于无法收敛. 所以我们改进牛顿法使得其步长可变,每一次都取得最合适的步长. 以此获得全局收敛性.

#### 共轭梯度法

- 优点
	- 一定会在n次内找到极小值点,具有二次终止性
	- 收敛速度较快
- 缺点
	- 只适用于严格凸二次函数

> 二次终止性: 求解正定的严格凸二次函数时一定会在有限步内取得最优解

共轭形式$$x_i^TAx_j = 0$$, 其中A为一个对称正定阵

##### 算法过程

求共轭方向作为每次迭代时的搜索方向, 为了满足迭代性, 将每一个方向与梯度以及之前的方向关联起来, 得到形如
$$
d_{n+1} = \nabla (f(x_n+1)) + \alpha(d_0)
$$
此处的` alpha`可以由几种公式得出,最简洁的应该是**Fletcher-Reeves**公式

Fletcher-Reeve公式:
$$
\alpha = \frac{||\nabla(f(x_{n+1}))||^2}{||\nabla(f(x_n))||^2}
$$
以及几种常见公式:

$Hestenes-Stiefel$公式;
$$
\alpha = \frac{(d^k)^TQ\nabla(f(x^{k+1}))}{(d^k)^TQd^k}
$$

#### 周期性共轭梯度法

使用FR方法时若初始方向选取的不是梯度的负方向, 可能无法取到n个共轭向量,所以需要在进行计算一定次数后将方向调整为当前点的负梯度方向

#### 拟牛顿法(变尺度法)(DFP算法&BFGS算法)

##### 拟牛顿方程

$$
\Delta \nabla y = A \Delta x / \Delta x = A^{-1}\Delta \nabla y\\其中A为\nabla^2f(x)
$$

令$$\Delta \nabla y = \gamma$$, $$ \Delta x = \delta$$

在秩1算法中,重要记忆点是u的值, $$ u=\delta_k - H_{k-1}\gamma_k$$  ,而迭代公式整体为$$ H_{k+1} = H_k + \alpha_k u u^T$$  , 剩下的只需要几步推导即可. 

##### 秩1算法

秩1算法是寻求$$(\nabla^2 f(x))^{-1}$$的近似矩阵, 突破点是矩阵迭代的式子.

然而由于秩1算法不一定能保证下一个近似矩阵的正定性,所以无法保证每一次迭代方向都是向下的.因此我们更多的采用DFP以及BFGS算法

记住,**DFP算法的性质要比BFGS优越,所以判断题说这两者的区别一般都是选BFGS的优点**

##### DFP算法(秩2算法)

DFP算法是寻求$$(\nabla^2 f(x))^{-1}$$的近似矩阵

从名字就能看出来DFP算法比前一个多设了一个矩阵, 迭代形式为 $$ H_{k+1} = H_k + \alpha u_k u_k^T + \beta v_k v_k^T$$  , 最后推导出的结果为
$$
H_{k+1} = H_k + \frac{\delta_{k+1}\delta_{k+1}^T}{\delta_{k+1}^T \gamma_{k+1}} - \frac{H_k \gamma_{k+1} \gamma_{k+1}^T H_{k}}{\gamma_{k+1}^T H_k \gamma_{k+1}}
$$
DFP算法的优点与函数性质有紧密联系:

- 若函数为二次严格凸函数, 则产生的方向是共轭的, 也就是说此时算法具有二次终止性
- 若函数至少一阶连续可微的严格凸函数, 则算法全局收敛
- 可以在梯度不为零的前提下保持近似矩阵正定,也就是说可以保证搜索方向是一直向下的
- 没有秩1算法中分母为零或近似为零的情况了

##### BFGS算法

DFP算法是寻求$$(\nabla^2 f(x))$$的近似矩阵, 迭代形式为 $$ H_{k+1} = H_k + \alpha u_k u_k^T + \beta v_k v_k^T$$  , 最后推导出的结果为

### 约束优化算法

#### 约束最优性条件

Lagrange算子

##### K-T点以及K-T约束条件

对于函数$f(x)$, 约束条件(不等以及等式约束)$g_i(x), h_i(x)$,  有Lagrange系数使得
$$
\nabla f(x) + \sum_{i}^n u_i\nabla g_i(x) + \sum_{i}^n v_i\nabla h_i(x) = 0
$$
同时有
$$
\sum_{i}^n u_i g_i(x) = 0\\u_i \geq 0
$$
此时满足的点$x^*$被称为满足K-T点的可行点

### 罚函数法

罚函数法将问题转化为无约束优化问题,分为外点罚函数法, 内点罚函数法, 混合罚函数法等

#### 外点罚函数法

构造罚函数时构造为
$$
F(x) = f(x) + \sum _i^n\rho h_i^2(x) + \sum_i^n \rho [max\{0, g_i(x)\}]^2
$$
然后将其当作无约束优化问题计算

- 缺点
	- 每个近似解可能不是可行解
	- 为了更精准需要更大的$\rho$,  但是也会增大增光目标函数Hesse矩阵的求解难度

#### 内点罚函数法

> 只适用于不等式约束的题目









## 例题(理论部分)

1. 

![图1](图1.png)



- 说法错误,我们只要求基变量的取值非负,不一定是正数



2. 

![图1-1](图1-1-3035057.png)

- 可行解存在只需要可行域不为空即可,此处y与前面的变量之间没有关联,可以找到可行解

3. **在用大M法求解LP问题的过程中，一旦某个人工变量在迭代中变为自由变量，那么该变量所在的列可以从单纯形表中删除，而不影响计算结果。**

- 确实, 此时说明该人工变量的系数为零,已经不对函数产生约束

4. 
