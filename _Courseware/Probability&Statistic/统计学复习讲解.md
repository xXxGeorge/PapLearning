《应用统计学》期末复习文档（扩展详解版）

本复习文档以知识整合与深入讲解为目标，系统梳理《应用统计学》课程中的核心概念与方法，并结合材料中涉及的重点内容，逐一讲解公式、方法的原理、优缺点，并辅以例子，帮助考生全面理解考试要点。

---

## 一、数理统计基础

### 1. 总体、样本与统计量

- **总体（Population）**：研究对象的全集，例如全国大学生身高。
- **样本（Sample）**：从总体中抽取的部分单位。
- **统计量（Statistic）**：从样本数据计算的数值，如：
  - 样本均值：\( \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i \)
  - 样本方差：\( s^2 = \frac{1}{n - 1} \sum_{i=1}^n (x_i - \bar{x})^2 \)
  - 样本原点矩：\( \mu_k' = \frac{1}{n} \sum_{i=1}^n x_i^k \)
  - 样本中心矩：\( \mu_k = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^k \)

### 2. 三大分布与三个引理

#### （1）卡方分布
若 \( Z_1, Z_2, \dots, Z_k \sim N(0,1) \) 独立，则：
\[ \chi^2_k = \sum_{i=1}^k Z_i^2 \sim \chi^2(k) \]
- 常用于方差估计、卡方独立性检验。
- 非负，右偏，自由度越大越接近正态。

#### （2）t 分布
若 \( Z \sim N(0,1), U \sim \chi^2(n) \)，且 \(Z\) 与 \(U\) 独立，则：
\[ T = \frac{Z}{\sqrt{U/n}} \sim t(n) \]
- 用于小样本条件下均值比较。
- 自由度越大，越接近标准正态分布。

#### （3）F 分布
若 \( U_1 \sim \chi^2(n_1), U_2 \sim \chi^2(n_2) \) 且独立，则：
\[ F = \frac{(U_1/n_1)}{(U_2/n_2)} \sim F(n_1, n_2) \]
- 应用于回归模型显著性检验和方差齐性检验。

---

## 二、参数估计与假设检验

### 1. 点估计方法

#### （1）矩估计法（Method of Moments）
- 原理：使样本矩等于总体矩，求出参数解。
- 优点：计算简单；缺点：不一定是最优估计。

#### （2）极大似然估计（MLE）
- 构造似然函数：\( L(\theta) = \prod_{i=1}^n f(x_i; \theta) \)
- 取对数并求导：\( \frac{d}{d\theta} \log L(\theta) = 0 \)
- 优点：有良好渐近性质（无偏、一致、有效）
- 缺点：计算量较大，分布形式需已知。

### 2. 区间估计

#### （1）已知方差时，估计均值 \( \mu \)
\[ \bar{X} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}} \]

#### （2）未知方差时，估计均值 \( \mu \)
\[ \bar{X} \pm t_{\alpha/2, n-1} \cdot \frac{S}{\sqrt{n}} \]

#### （3）估计总体方差
\[ \left( \frac{(n - 1)S^2}{\chi^2_{1 - \alpha/2}}, \frac{(n - 1)S^2}{\chi^2_{\alpha/2}} \right) \]

### 3. 假设检验与 p 值

- **p 值定义**：在原假设 \( H_0 \) 成立的前提下，观察到现有样本结果或更极端结果的概率。
- **检验流程**：设定 \( H_0, H_1 \) → 计算统计量 → 求 p 值 → 与显著性水平 \( \alpha \) 比较。

#### 举例：
检验某药物是否影响血压，设：
\[ H_0: \mu = 120, \quad H_1: \mu \ne 120 \]
若样本均值为 125，p 值为 0.01，\( \alpha = 0.05 \)，则拒绝原假设。

---

## 三、线性回归分析

### 1. 模型结构
- \( Y = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p + \varepsilon \)
- \( \varepsilon \sim N(0, \sigma^2 I) \)，为独立同分布误差项。

### 2. 最小二乘估计（OLS）
\[ \hat{\beta} = (X^TX)^{-1}X^TY \]
- 优点：简单直观、具有 BLUE 性质（最优线性无偏估计）
- 缺点：对共线性、异方差、异常值敏感

### 3. 模型评价指标
- 回归系数：\( \beta_j \) 代表 \( X_j \) 的边际影响
- 决定系数：
\[ R^2 = 1 - \frac{SSE}{SST} = \frac{SSR}{SST} \]
- 调整决定系数：
\[ R^2_{adj} = 1 - \frac{SSE / (n - p)}{SST / (n - 1)} \]

### 4. 平方和定义
- 总平方和（SST）：\( \sum (y_i - \bar{y})^2 \)
- 回归平方和（SSR）：\( \sum (\hat{y}_i - \bar{y})^2 \)
- 残差平方和（SSE）：\( \sum (y_i - \hat{y}_i)^2 \)

---

## 四、多重共线性及其处理

### 1. 问题描述
多重共线性指自变量之间存在较强的线性相关性。

### 2. 判别方法
- **相关系数矩阵**：检查是否存在高于 0.8 或低于 -0.8 的相关性。
- **VIF**：\( VIF_j = \frac{1}{1 - R_j^2} \)，若 > 10，说明共线性严重。
- **条件数**：\( \kappa = \sqrt{\lambda_{\max}/\lambda_{\min}} \)，> 30 说明共线性严重。

### 3. 解决方法对比
- 删除变量：直接去掉高相关变量，简洁但可能损失信息。
- 岭回归：引入 \( L_2 \) 惩罚项 \( \lambda \sum \beta_j^2 \)，控制系数大小；
  - 优点：稳定系数，缓解共线性；
  - 缺点：不能进行变量选择（所有变量保留）。
- Lasso：加入 \( L_1 \) 惩罚项 \( \lambda \sum |\beta_j| \)，部分系数变为 0；
  - 优点：可做变量选择，适用于高维数据；
  - 缺点：解不唯一，变量间高度相关时表现差。
- 弹性网（Elastic Net）：兼具 Lasso 与 Ridge 的优点。

---

## 五、模型诊断与改进

### 1. 异方差性

#### 判断方法：
- 残差图是否呈漏斗状（残差随预测值变化扩大或缩小）
- Breusch-Pagan 检验、White 检验

#### 处理方法：
- 对 Y 或 X 做对数或平方根变换
- 加权最小二乘法（WLS）：使用权重 \( w_i = 1/Var(\varepsilon_i) \)
- 使用稳健标准误估计：如 HC0、HC3 等

### 2. 虚拟变量处理

对于类别型变量，使用哑变量（dummy variable）转换成数值型变量。
例如“学历”有三类：“高中、本科、研究生”：
- D1 = 1（本科），0 否
- D2 = 1（研究生），0 否
（高中作为参考组）

### 3. 残差与影响分析
- 普通残差：\( e_i = y_i - \hat{y}_i \)
- 标准化残差：除以其标准误差
- 杠杆值 \( h_{ii} \)：表示观测值对拟合的影响力
- Cook 距离 \( D_i \)：综合残差与杠杆值判断异常点

---

## 六、重抽样与非参数方法

### 1. Bootstrap

- 方法：对样本重复有放回抽样，计算目标统计量形成估计分布
- 优点：无需分布假设，适合小样本
- 示例：用 Bootstrap 估计样本均值的置信区间

### 2. Jackknife

- 方法：每次剔除一个样本点重新计算估计量
- 优点：计算简便、适合偏差估计

### 3. 交叉验证

- K 折交叉验证（K-fold）：将数据分为 K 份，轮流验证
- 留一交叉验证（LOOCV）：每次留一个观测验证
- 广义交叉验证（GCV）：无需实际划分数据，适合岭回归等

---

## 七、Logistic 回归模型

适用于因变量为 0/1 分类变量。

### 1. 模型结构
\[ P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \dots + \beta_p X_p)}} \]
- 使用极大似然估计求解 \( \beta \)

### 2. 模型评估指标
- **混淆矩阵**：分类结果统计表（TP, FP, FN, TN）
- **准确率**：\( \frac{TP + TN}{总数} \)
- **精确率（Precision）**：\( \frac{TP}{TP + FP} \)
- **召回率（Recall）**：\( \frac{TP}{TP + FN} \)
- **F1 分数**：调和平均 \( F1 = 2 \cdot \frac{PR}{P + R} \)
- **ROC 曲线与 AUC**：综合评价模型分类性能

### 3. 正则化方法
- L1（Lasso）：可用于特征选择
- L2（Ridge）：提高模型稳定性，保留所有变量
- Elastic Net：权衡两者，适合变量多、相关性强的场景

---

如需继续添加内容（如例题演练、考试策略），请提出具体要求。

